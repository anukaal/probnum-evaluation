{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corporate-farming",
   "metadata": {},
   "source": [
    "# Quantify approximation error and calibration of a PN Method\n",
    "\n",
    "This notebook explains how to use the functions in probnum-evaluation to quantify the approximation error as well as the uncertainty calibration of the output of a probabilistic numerical method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fatty-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probnum import quad, diffeq\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorrect-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probnumeval import multivariate, timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-amino",
   "metadata": {},
   "source": [
    "## One-dimensional example\n",
    "\n",
    "The first example shall be Bayesian quadrature, which computes a probabilistic numerical solution of (e.g.) the integral\n",
    "\n",
    "$$\n",
    "F = \\int_0^\\pi \\sin(x) \\,\\text{d}x.\n",
    "$$\n",
    "\n",
    "The true solution of this integral is $F = 2.0$. Begin by setting the problem up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "welsh-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "domain = (0, np.pi)\n",
    "\n",
    "# Define the integrand\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "\n",
    "# True solution of \\int_0^\\pi sin(x) dx is 2.0\n",
    "sol = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-gates",
   "metadata": {},
   "source": [
    "The solution of this integration problem is computed with `probnum.quad` (https://probnum.readthedocs.io/en/latest/public_api/quad.html). Let us only use few function evaluations, so the solution is sufficiently inaccurate and the covariance of the output will be $\\gg 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "focal-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "F, _ = quad.bayesquad(fun=f, input_dim=input_dim, domain=domain, nevals=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-finland",
   "metadata": {},
   "source": [
    "In `ProbNum-Evaluation`, finite-dimensional outputs (such as $F$) are quantified with `probnumeval.multivariate`. Among other things, this module contains error measures such as root mean-square errors (RMSEs), mean absolute errors, or their relative counterparts. \n",
    "For instance, the RMSE and relative RMSE are computed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mexican-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06127865361488327 0.030639326807441636\n"
     ]
    }
   ],
   "source": [
    "rmse = multivariate.rmse(F.mean, reference_solution=sol)\n",
    "relative_rmse = multivariate.relative_rmse(F.mean, reference_solution=sol)\n",
    "print(rmse, relative_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-reducing",
   "metadata": {},
   "source": [
    "We can also check how well the covariance quantifies the approximation error -- for instance, with the averaged normalised estimation error squared (ANEES). A value close to 1 is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entire-reasoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12591126045245504\n"
     ]
    }
   ],
   "source": [
    "anees = multivariate.anees(F, reference_solution=sol)\n",
    "print(anees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-majority",
   "metadata": {},
   "source": [
    "## Time-series example\n",
    "\n",
    "The same functionality can be used for a more complex posterior.\n",
    "The next example is a probabilistic numerical ODE solution of \n",
    "\n",
    "$$\n",
    "\\dot y(t) = y(t) * (1 - y(t)), \\quad y(0) = 0.5\n",
    "$$\n",
    "\n",
    "for $t\\in (0.0, 5.0)$. This logistic ODE has the analytic solution\n",
    "\n",
    "$$\n",
    "y(t) = \\frac{y_0 e^t}{1 + y_0 (e^t - 1)}.\n",
    "$$\n",
    "\n",
    "Let us begin by setting up the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "analyzed-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t, x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "y0 = np.array([0.5])\n",
    "\n",
    "\n",
    "t0 = 0.0\n",
    "tmax = 5.0\n",
    "\n",
    "\n",
    "def sol(t):\n",
    "    return (y0 * np.exp(t)) / (1 + y0 * (np.exp(t) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-receptor",
   "metadata": {},
   "source": [
    "In `ProbNum`, ODEs are solved with `probnum.diffeq`. The outputs are usually `TimeSeriesPosterior`, i.e. functions that carry the states of the solution at a grid, and can also be called at any input.\n",
    "To evaluate the posterior, let us include the zeroth point of the domain (which is error-free by construction, and has covariance zero). If we did not do this, computation of calibration indices may be subject to numerical instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elegant-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnsol = diffeq.probsolve_ivp(f, y0=y0, t0=t0, tmax=tmax)\n",
    "\n",
    "approx_sol = pnsol.states[1:]\n",
    "true_sol = sol(pnsol.locations[1:])[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-stamp",
   "metadata": {},
   "source": [
    "On the given set of evaluations of the solution, we can compute any error measure. This time, we choose the mean absolute error (MAE) and its relative counterpart, the relative MAE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vanilla-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006241640303712251 0.0006614154047129657\n"
     ]
    }
   ],
   "source": [
    "mae = multivariate.mae(approx_sol.mean, true_sol)\n",
    "relative_mae = multivariate.relative_mae(approx_sol.mean, true_sol)\n",
    "print(mae, relative_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-tractor",
   "metadata": {},
   "source": [
    "Since covariances of ODE solutions can be ill-conditioned, we make sure that all the covariance calculations use pseudo-inverses.\n",
    "This step is totally optional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vertical-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probnumeval import config\n",
    "\n",
    "config.set_covariance_inversion_parameters(\n",
    "    strategy=\"pinv\", symmetrize=True, damping=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-strain",
   "metadata": {},
   "source": [
    "We can also quantify the uncertainty calibration, for instance by calling the ANEES again.\n",
    "This time however, we opt for the non-credibility index and the inclination index.\n",
    "The difference to the ANEES is that NCI and II compare the calibration of the posterior to a \"reference calibration\", and thus respond differently to optimism and pessimism.\n",
    "The difference between NCI and II is that NCI is an absolute number (the lower the better), whereas the II indicates over- and underconfidence. For both values, the closer to zero the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hidden-hungary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.803778627298394 11.306190199210022\n"
     ]
    }
   ],
   "source": [
    "nci = multivariate.non_credibility_index(approx_sol, true_sol)\n",
    "ii = multivariate.inclination_index(approx_sol, true_sol)\n",
    "print(nci, ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-microphone",
   "metadata": {},
   "source": [
    "All of the above could have been obtained by applying the `timeseries` module to the (callable) ODE posteriors. While the `multivariate` module expects (lists of) random variables, the `timeseries` acts directly on the ODE solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chemical-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006241640303712251 0.0006614154047129657 12.803778627298394 11.306190199210022\n"
     ]
    }
   ],
   "source": [
    "# Reshape the reference solution to match it to the ODE solution\n",
    "def sol_reshaped(*args, **kwargs):\n",
    "    return sol(*args, **kwargs)[:, None]\n",
    "\n",
    "\n",
    "# Extract the mean function from the PN solution.\n",
    "def pnsol_mean(*args, **kwargs):\n",
    "    return pnsol(*args, **kwargs).mean\n",
    "\n",
    "\n",
    "mae = timeseries.mae(pnsol_mean, sol_reshaped, locations=pnsol.locations[1:])\n",
    "relative_mae = timeseries.relative_mae(\n",
    "    pnsol_mean, sol_reshaped, locations=pnsol.locations[1:]\n",
    ")\n",
    "\n",
    "nci = timeseries.non_credibility_index(\n",
    "    pnsol, sol_reshaped, locations=pnsol.locations[1:]\n",
    ")\n",
    "ii = timeseries.inclination_index(pnsol, sol_reshaped, locations=pnsol.locations[1:])\n",
    "print(mae, relative_mae, nci, ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-station",
   "metadata": {},
   "source": [
    "**Summary** \n",
    "\n",
    "`Probnum-Evaluation` contains a wide range of measures for quantifying approximation error and uncertainty calibration.\n",
    "The measures for evaluating (finite-dimensional) random variables are in `multivariate`.\n",
    "The measures for evaluating processes directly are in `timeseries`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-aging",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
